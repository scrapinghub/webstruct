{
 "metadata": {
  "name": "train-token-model"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import re\n",
      "import codecs\n",
      "import random\n",
      "import itertools\n",
      "\n",
      "sys.path.insert(0, '../../webstruct/')\n",
      "\n",
      "import wapiti\n",
      "from webstruct.feature_extraction import HtmlFeaturesExtractor\n",
      "from webstruct.wapiti import WapitiFeatureEncoder"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tagged_data(folder):\n",
      "    for fname in os.listdir(folder):\n",
      "        path = os.path.join(folder, fname)\n",
      "        with codecs.open(path, 'r', encoding='utf8') as f:\n",
      "            yield path, f.read()\n",
      "            \n",
      "\n",
      "def fit_wapiti_encoder(tagged_data_iter):\n",
      "    fe = HtmlFeaturesExtractor()\n",
      "    we = WapitiFeatureEncoder(['token', 'lower'])    \n",
      "    for path, html in tagged_data_iter:\n",
      "        try:\n",
      "            features, labels = fe.fit_transform(html)\n",
      "            we.partial_fit(features)\n",
      "        except AssertionError as e:\n",
      "            print(\"error decoding %s:\\n%s\" % (path, e))\n",
      "    return we\n",
      "\n",
      "\n",
      "def to_wapiti_seq(features, labels, include_labels=True):\n",
      "    lines = []\n",
      "    for line, label in zip(we.transform(features), labels):\n",
      "        if include_labels:\n",
      "            lines.append(\"%s %s\" % (line, label))\n",
      "        else:\n",
      "            lines.append(line)\n",
      "    return '\\n'.join(lines)\n",
      "    \n",
      "\n",
      "def iter_wapiti_sequences(tagged_data_iter, we, include_labels=True):\n",
      "    fe = HtmlFeaturesExtractor()\n",
      "    for path, html in tagged_data_iter:\n",
      "        try:\n",
      "            features, labels = fe.fit_transform(html)\n",
      "        except AssertionError as e:\n",
      "            print(\"error decoding %s:\\n%s\" % (path, e))\n",
      "        else:\n",
      "            yield to_wapiti_seq(features, labels, include_labels)\n",
      "        \n",
      "    \n",
      "def create_wapiti_data(fname, tagged_data_iter, we, include_labels=True):\n",
      "    with codecs.open(fname, 'w', encoding='utf8') as f:            \n",
      "        for seq in iter_wapiti_sequences(tagged_data_iter, we, include_labels):\n",
      "            f.write(seq)\n",
      "            f.write('\\n\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.seed(0)\n",
      "\n",
      "corpus_paths = [\n",
      "    '../webstruct_data/corpus/us_contact_pages/annotated',\n",
      "    '../webstruct_data/corpus/random_pages/annotated',    \n",
      "]\n",
      "data = list(itertools.chain(*map(tagged_data, corpus_paths)))\n",
      "\n",
      "TRAIN_SIZE = 70\n",
      "\n",
      "random.shuffle(data)\n",
      "train, dev = data[:130], data[130:]\n",
      "#train, dev = data[:], []\n",
      "\n",
      "print(len(train), len(dev))\n",
      "\n",
      "we = fit_wapiti_encoder(train)\n",
      "\n",
      "create_wapiti_data('train130.txt', train, we=we)\n",
      "create_wapiti_data('dev130.txt', dev, we=we)\n",
      "\n",
      "from sklearn.externals.joblib import dump\n",
      "#dump(we, 'wfe-155.joblib', compress=1)\n",
      "dump(we, 'wfe130.joblib', compress=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(130, 25)"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "template = '''\n",
      "# Label unigram & bigram\n",
      "*\n",
      "\n",
      "# Nearby token unigrams (lower)\n",
      "u-LL:%x[-2,lower]\n",
      "u--L:%x[-1,lower]\n",
      "u--R:%x[ 1,lower]\n",
      "u-RR:%x[ 2,lower]\n",
      "\n",
      "# Bag of Words\n",
      "#u:bow_left:%x[-4,lower]\n",
      "#u:bow_left:%x[-3,lower]\n",
      "#u:bow_left:%x[-2,lower]\n",
      "#u:bow_left:%x[-1,lower]\n",
      "#u:bow_right:%x[1,lower]\n",
      "#u:bow_right:%x[2,lower]\n",
      "#u:bow_right:%x[3,lower]\n",
      "#u:bow_right:%x[4,lower]\n",
      "\n",
      "# Nearby token bigrams (lower)\n",
      "#*bigram_left:%x[-2,lower]/%x[-1,lower]\n",
      "#*bigram_right:%x[1,lower]/%x[2,lower]\n",
      "\n",
      "# Nearby shapes\n",
      "u:shape-LL:%x[-2,shape]\n",
      "u:shape--L:%x[-1,shape]\n",
      "u:shape--R:%x[1,shape]\n",
      "u:shape-RR:%x[2,shape]\n",
      "\n",
      "#u:shape:%x[-1,shape]/%x[0,shape]\n",
      "#u:s4:%x[-2,shape]/%x[-1,shape]/%x[0,shape]\n",
      "#u:s5:%x[-3,shape]/%x[-2,shape]/%x[0,shape]\n",
      "\n",
      "# Nearby numeric patterns\n",
      "u:pattern-LL:%x[-2,num_pattern2]\n",
      "u:pattern--L:%x[-1,num_pattern2]\n",
      "u:pattern--R:%x[ 1,num_pattern2]\n",
      "u:pattern-RR:%x[ 2,num_pattern2]\n",
      "\n",
      "# Numeric pattern + previous token\n",
      "# u:pattern-and-token:%x[-1, lower]/%x[0,num_pattern2]\n",
      "\n",
      "# Likely dates\n",
      "#u:date1:%x[-1,looks_like_year]/%x[0,looks_like_month]\n",
      "#u:date2:%x[-1,looks_like_month]/%x[0,looks_like_year]\n",
      "u:month_before:%x[-1,looks_like_month]\n",
      "'''\n",
      "\n",
      "wapiti_template = we.unigram_features_template() + we.prepare_template(template) \n",
      "\n",
      "with codecs.open('wapiti-template.txt', 'w', encoding='utf8') as f:\n",
      "    f.write(wapiti_template)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%alias wapiti_train wapiti train --pattern wapiti-template.txt --compact --nthread 4 --jobsize 8"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###First, train the model using fast SGD algorithm to find a good starting point.\n",
      "\n",
      "--eta0 is learning rate; non-default value is crucial here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wapiti_train --maxiter 7 --eta0 0.001 --devel dev130.txt --algo sgd-l1 train130.txt model-sgd130.wapiti"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Load patterns\r\n",
        "* Load training data\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Load development data\r\n",
        "error: cannot open development file\r\n",
        "\t<No such file or directory>\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Then refine the model using L-BFGS algorithm. \n",
      "\n",
      "Warning: if requries *a lot* of memory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wapiti_train --histsz 2 --devel dev130.txt --model model-sgd130.wapiti --maxiter 35 --algo l-bfgs train130.txt model130.wapiti"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Load previous model\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Load patterns\r\n",
        "* Load training data\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Load development data\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Resync the model\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Summary\r\n",
        "    nb train:    130\r\n",
        "    nb devel:    25\r\n",
        "    nb labels:   27\r\n",
        "    nb blocks:   126224\r\n",
        "    nb features: 49604049\r\n",
        "* Train the model with l-bfgs\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  [   1] obj=8731.45    act=186157   err= 6.71%/100.00% time=110.05s/110.05s\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  [   2] obj=8415.02    act=183207   err= 6.69%/100.00% time=105.47s/215.53s\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "^C\r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Quick check:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wapiti label --model model130.wapiti -c dev130.txt res.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Load model\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Label sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    Nb sequences  : 25\r\n",
        "    Token error   :  4.97%\r\n",
        "    Sequence error: 100.00%\r\n",
        "* Per label statistics\r\n",
        "    O       Pr=0.96  Rc=0.99  F1=0.98\r\n",
        "    B-STREET  Pr=0.86  Rc=0.76  F1=0.81\r\n",
        "    I-STREET  Pr=0.71  Rc=0.65  F1=0.68\r\n",
        "    B-ZIPCODE  Pr=1.00  Rc=0.89  F1=0.94\r\n",
        "    I-ZIPCODE  Pr=1.00  Rc=0.50  F1=0.67\r\n",
        "    B-CITY  Pr=0.89  Rc=0.76  F1=0.82\r\n",
        "    B-TEL   Pr=0.94  Rc=0.88  F1=0.91\r\n",
        "    I-TEL   Pr=0.92  Rc=0.92  F1=0.92\r\n",
        "    B-EMAIL  Pr=0.96  Rc=0.64  F1=0.77\r\n",
        "    B-ORG   Pr=0.67  Rc=0.43  F1=0.52\r\n",
        "    I-ORG   Pr=0.56  Rc=0.44  F1=0.49\r\n",
        "    B-COUNTRY  Pr=1.00  Rc=0.50  F1=0.67\r\n",
        "    I-CITY  Pr=0.91  Rc=0.62  F1=0.74\r\n",
        "    B-STATE  Pr=0.97  Rc=0.91  F1=0.94\r\n",
        "    I-STATE  Pr=0.00  Rc=nan  F1=nan\r\n",
        "    B-SUBJ  Pr=0.79  Rc=0.28  F1=0.42\r\n",
        "    I-SUBJ  Pr=0.61  Rc=0.26  F1=0.37\r\n",
        "    B-PER   Pr=nan  Rc=0.00  F1=nan\r\n",
        "    I-PER   Pr=nan  Rc=0.00  F1=nan\r\n",
        "    B-FAX   Pr=0.92  Rc=0.52  F1=0.67\r\n",
        "    B-HOURS  Pr=0.67  Rc=0.31  F1=0.42\r\n",
        "    I-HOURS  Pr=0.95  Rc=0.59  F1=0.73\r\n",
        "    I-FAX   Pr=0.72  Rc=0.62  F1=0.67\r\n",
        "    B-FUNC  Pr=nan  Rc=nan  F1=nan\r\n",
        "    I-FUNC  Pr=nan  Rc=nan  F1=nan\r\n",
        "    I-COUNTRY  Pr=nan  Rc=nan  F1=nan\r\n",
        "    I-EMAIL  Pr=nan  Rc=0.00  F1=nan\r\n",
        "* Done\r\n"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}